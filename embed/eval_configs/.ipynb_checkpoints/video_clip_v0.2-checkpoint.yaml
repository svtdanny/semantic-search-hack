model:
  arch: video_llama
  model_type: pretrain_vicuna
  ckpt: './models/askvideos_clip_v0.2.pth'
  max_frame_pos: 32
  clip_dim_size: 1024
  num_videoq_hidden_layers: 4


datasets:
  webvid:
    vis_processor:
      train:
        name: "alpro_video_eval"
        n_frms: 32
        image_size: 224
    text_processor:
      train:
        name: "blip_caption"

run:
  task: video_text_pretrain
